[
  {
    "algo":"A2C",
    "run_name":"run_01",
    "metadata_source":"run",
    "training_walltime_sec":756.0508515,
    "eval_mean_reward":110.162499875,
    "eval_std_reward":50.6107157729,
    "callback_best_mean_reward":86.766666625,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0005,
      "gamma":0.98,
      "n_steps":8,
      "gae_lambda":0.9,
      "ent_coef":0.005,
      "vf_coef":0.5,
      "max_grad_norm":0.5,
      "policy_kwargs":{
        "net_arch":[
          256,
          128
        ],
        "activation_fn":"ReLU",
        "ortho_init":false
      },
      "total_timesteps":180000
    },
    "best_model_path":"models\\a2c\\run_01\\best_model\\best_model.zip",
    "final_model_path":"models\\a2c\\run_01\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":180000.0,
    "eval_callback_mean":86.766666625,
    "eval_callback_std":48.6448095596,
    "mean_ep_length":50.0,
    "source_file":"a2c\\run_01\\eval_logs\\evaluations.npz",
    "score_for_rank":110.162499875,
    "reward_rank":1.0
  },
  {
    "algo":"A2C",
    "run_name":"run_03",
    "metadata_source":"run",
    "training_walltime_sec":715.1821788,
    "eval_mean_reward":102.075000125,
    "eval_std_reward":46.9412095095,
    "callback_best_mean_reward":100.183333375,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0009,
      "gamma":0.97,
      "n_steps":10,
      "gae_lambda":0.92,
      "ent_coef":0.015,
      "vf_coef":0.4,
      "max_grad_norm":0.5,
      "policy_kwargs":{
        "net_arch":[
          256,
          256
        ],
        "activation_fn":"ReLU",
        "ortho_init":false
      },
      "total_timesteps":180000
    },
    "best_model_path":"models\\a2c\\run_03\\best_model\\best_model.zip",
    "final_model_path":"models\\a2c\\run_03\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":180000.0,
    "eval_callback_mean":52.479166625,
    "eval_callback_std":38.9505702702,
    "mean_ep_length":50.0,
    "source_file":"a2c\\run_03\\eval_logs\\evaluations.npz",
    "score_for_rank":102.075000125,
    "reward_rank":2.0
  },
  {
    "algo":"A2C",
    "run_name":"run_09",
    "metadata_source":"run",
    "training_walltime_sec":1101.9494513,
    "eval_mean_reward":88.69583325,
    "eval_std_reward":60.7273286242,
    "callback_best_mean_reward":122.662500125,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.00035,
      "gamma":0.99,
      "n_steps":5,
      "gae_lambda":0.96,
      "ent_coef":0.0,
      "vf_coef":0.5,
      "max_grad_norm":0.6,
      "policy_kwargs":{
        "net_arch":[
          256,
          256,
          128
        ],
        "activation_fn":"Tanh",
        "ortho_init":true
      },
      "total_timesteps":180000
    },
    "best_model_path":"models\\a2c\\run_09\\best_model\\best_model.zip",
    "final_model_path":"models\\a2c\\run_09\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":180000.0,
    "eval_callback_mean":-28.895833375,
    "eval_callback_std":27.2514091657,
    "mean_ep_length":50.0,
    "source_file":"a2c\\run_09\\eval_logs\\evaluations.npz",
    "score_for_rank":88.69583325,
    "reward_rank":3.0
  },
  {
    "algo":"A2C",
    "run_name":"run_07",
    "metadata_source":"run",
    "training_walltime_sec":968.6377549,
    "eval_mean_reward":67.833333375,
    "eval_std_reward":53.4954851412,
    "callback_best_mean_reward":82.695833125,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0008,
      "gamma":0.97,
      "n_steps":5,
      "gae_lambda":0.9,
      "ent_coef":0.02,
      "vf_coef":0.4,
      "max_grad_norm":0.5,
      "policy_kwargs":{
        "net_arch":[
          256,
          256
        ],
        "activation_fn":"ReLU",
        "ortho_init":false
      },
      "total_timesteps":180000
    },
    "best_model_path":"models\\a2c\\run_07\\best_model\\best_model.zip",
    "final_model_path":"models\\a2c\\run_07\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":180000.0,
    "eval_callback_mean":82.695833125,
    "eval_callback_std":42.3367138878,
    "mean_ep_length":50.0,
    "source_file":"a2c\\run_07\\eval_logs\\evaluations.npz",
    "score_for_rank":67.833333375,
    "reward_rank":4.0
  },
  {
    "algo":"A2C",
    "run_name":"run_05",
    "metadata_source":"run",
    "training_walltime_sec":754.9265871,
    "eval_mean_reward":57.6666665,
    "eval_std_reward":51.8715133601,
    "callback_best_mean_reward":112.6,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0006,
      "gamma":0.99,
      "n_steps":8,
      "gae_lambda":0.97,
      "ent_coef":0.0,
      "vf_coef":0.5,
      "max_grad_norm":0.6,
      "policy_kwargs":{
        "net_arch":[
          256,
          256
        ],
        "activation_fn":"ELU",
        "ortho_init":true
      },
      "total_timesteps":180000
    },
    "best_model_path":"models\\a2c\\run_05\\best_model\\best_model.zip",
    "final_model_path":"models\\a2c\\run_05\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":180000.0,
    "eval_callback_mean":112.6,
    "eval_callback_std":41.9751315896,
    "mean_ep_length":50.0,
    "source_file":"a2c\\run_05\\eval_logs\\evaluations.npz",
    "score_for_rank":57.6666665,
    "reward_rank":5.0
  },
  {
    "algo":"A2C",
    "run_name":"run_06",
    "metadata_source":"run",
    "training_walltime_sec":670.4728963,
    "eval_mean_reward":51.90833325,
    "eval_std_reward":77.9941873623,
    "callback_best_mean_reward":41.95,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0002,
      "gamma":0.995,
      "n_steps":10,
      "gae_lambda":0.95,
      "ent_coef":0.002,
      "vf_coef":0.6,
      "max_grad_norm":0.6,
      "policy_kwargs":{
        "net_arch":[
          256,
          128
        ],
        "activation_fn":"Tanh",
        "ortho_init":true
      },
      "total_timesteps":180000
    },
    "best_model_path":"models\\a2c\\run_06\\best_model\\best_model.zip",
    "final_model_path":"models\\a2c\\run_06\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":180000.0,
    "eval_callback_mean":41.95,
    "eval_callback_std":43.5729465278,
    "mean_ep_length":50.0,
    "source_file":"a2c\\run_06\\eval_logs\\evaluations.npz",
    "score_for_rank":51.90833325,
    "reward_rank":6.0
  },
  {
    "algo":"A2C",
    "run_name":"run_00",
    "metadata_source":"run",
    "training_walltime_sec":1004.1110772,
    "eval_mean_reward":34.1,
    "eval_std_reward":48.2845557326,
    "callback_best_mean_reward":27.875,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0007,
      "gamma":0.99,
      "n_steps":5,
      "gae_lambda":0.95,
      "ent_coef":0.01,
      "vf_coef":0.5,
      "max_grad_norm":0.5,
      "policy_kwargs":{
        "net_arch":[
          256,
          256
        ],
        "activation_fn":"ReLU",
        "ortho_init":true
      },
      "total_timesteps":180000
    },
    "best_model_path":"models\\a2c\\run_00\\best_model\\best_model.zip",
    "final_model_path":"models\\a2c\\run_00\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":180000.0,
    "eval_callback_mean":2.975,
    "eval_callback_std":33.3515607707,
    "mean_ep_length":50.0,
    "source_file":"a2c\\run_00\\eval_logs\\evaluations.npz",
    "score_for_rank":34.1,
    "reward_rank":7.0
  },
  {
    "algo":"A2C",
    "run_name":"run_02",
    "metadata_source":"run",
    "training_walltime_sec":845.3615472,
    "eval_mean_reward":-17.5625,
    "eval_std_reward":38.5776793871,
    "callback_best_mean_reward":5.204166625,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0003,
      "gamma":0.995,
      "n_steps":5,
      "gae_lambda":0.96,
      "ent_coef":0.0,
      "vf_coef":0.6,
      "max_grad_norm":0.6,
      "policy_kwargs":{
        "net_arch":[
          256,
          256,
          128
        ],
        "activation_fn":"Tanh",
        "ortho_init":true
      },
      "total_timesteps":180000
    },
    "best_model_path":"models\\a2c\\run_02\\best_model\\best_model.zip",
    "final_model_path":"models\\a2c\\run_02\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":180000.0,
    "eval_callback_mean":5.204166625,
    "eval_callback_std":35.6565892549,
    "mean_ep_length":50.0,
    "source_file":"a2c\\run_02\\eval_logs\\evaluations.npz",
    "score_for_rank":-17.5625,
    "reward_rank":8.0
  },
  {
    "algo":"A2C",
    "run_name":"run_08",
    "metadata_source":"run",
    "training_walltime_sec":702.1170803,
    "eval_mean_reward":-27.78333325,
    "eval_std_reward":11.8805279434,
    "callback_best_mean_reward":-6.44166675,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.001,
      "gamma":0.96,
      "n_steps":8,
      "gae_lambda":0.9,
      "ent_coef":0.02,
      "vf_coef":0.5,
      "max_grad_norm":0.5,
      "policy_kwargs":{
        "net_arch":[
          128,
          128
        ],
        "activation_fn":"ReLU",
        "ortho_init":false
      },
      "total_timesteps":180000
    },
    "best_model_path":"models\\a2c\\run_08\\best_model\\best_model.zip",
    "final_model_path":"models\\a2c\\run_08\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":180000.0,
    "eval_callback_mean":-23.2083335,
    "eval_callback_std":27.8089151851,
    "mean_ep_length":50.0,
    "source_file":"a2c\\run_08\\eval_logs\\evaluations.npz",
    "score_for_rank":-27.78333325,
    "reward_rank":9.0
  },
  {
    "algo":"A2C",
    "run_name":"run_04",
    "metadata_source":"run",
    "training_walltime_sec":884.0291115,
    "eval_mean_reward":-149.12083325,
    "eval_std_reward":2.2020784767,
    "callback_best_mean_reward":-151.275000125,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0004,
      "gamma":0.98,
      "n_steps":5,
      "gae_lambda":0.95,
      "ent_coef":0.005,
      "vf_coef":0.5,
      "max_grad_norm":0.5,
      "policy_kwargs":{
        "net_arch":[
          128,
          128
        ],
        "activation_fn":"ReLU",
        "ortho_init":false
      },
      "total_timesteps":180000
    },
    "best_model_path":"models\\a2c\\run_04\\best_model\\best_model.zip",
    "final_model_path":"models\\a2c\\run_04\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":180000.0,
    "eval_callback_mean":-151.5541665,
    "eval_callback_std":2.761136018,
    "mean_ep_length":50.0,
    "source_file":"a2c\\run_04\\eval_logs\\evaluations.npz",
    "score_for_rank":-149.12083325,
    "reward_rank":10.0
  },
  {
    "algo":"DQN",
    "run_name":"run_08",
    "metadata_source":"run",
    "training_walltime_sec":1097.3827444001,
    "eval_mean_reward":189.7375,
    "eval_std_reward":44.9156322636,
    "callback_best_mean_reward":146.441666625,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0008,
      "gamma":0.95,
      "buffer_size":70000,
      "batch_size":64,
      "train_freq":2,
      "gradient_steps":1,
      "target_update_interval":600,
      "exploration_fraction":0.22,
      "exploration_final_eps":0.02,
      "learning_starts":1200,
      "policy_kwargs":{
        "net_arch":[
          128,
          128
        ],
        "activation_fn":"Tanh",
        "ortho_init":"sb3-default"
      },
      "total_timesteps":150000
    },
    "best_model_path":"models\\dqn\\run_08\\best_model\\best_model.zip",
    "final_model_path":"models\\dqn\\run_08\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":150000.0,
    "eval_callback_mean":146.441666625,
    "eval_callback_std":59.2481896622,
    "mean_ep_length":50.0,
    "source_file":"dqn\\run_08\\eval_logs\\evaluations.npz",
    "score_for_rank":189.7375,
    "reward_rank":1.0
  },
  {
    "algo":"DQN",
    "run_name":"run_00",
    "metadata_source":"run",
    "training_walltime_sec":396.258328,
    "eval_mean_reward":188.729166625,
    "eval_std_reward":40.4301744297,
    "callback_best_mean_reward":166.754166625,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.001,
      "gamma":0.95,
      "buffer_size":60000,
      "batch_size":64,
      "train_freq":4,
      "gradient_steps":1,
      "target_update_interval":500,
      "exploration_fraction":0.25,
      "exploration_final_eps":0.02,
      "learning_starts":1000,
      "policy_kwargs":{
        "net_arch":[
          256,
          256
        ],
        "activation_fn":"ReLU",
        "ortho_init":"sb3-default"
      },
      "total_timesteps":150000
    },
    "best_model_path":"models\\dqn\\run_00\\best_model\\best_model.zip",
    "final_model_path":"models\\dqn\\run_00\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":150000.0,
    "eval_callback_mean":166.754166625,
    "eval_callback_std":81.041134734,
    "mean_ep_length":50.0,
    "source_file":"dqn\\run_00\\eval_logs\\evaluations.npz",
    "score_for_rank":188.729166625,
    "reward_rank":2.0
  },
  {
    "algo":"DQN",
    "run_name":"run_05",
    "metadata_source":"run",
    "training_walltime_sec":1510.7048398999,
    "eval_mean_reward":157.862500125,
    "eval_std_reward":50.9656704156,
    "callback_best_mean_reward":141.96666675,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0009,
      "gamma":0.96,
      "buffer_size":70000,
      "batch_size":64,
      "train_freq":4,
      "gradient_steps":2,
      "target_update_interval":600,
      "exploration_fraction":0.25,
      "exploration_final_eps":0.015,
      "learning_starts":1200,
      "policy_kwargs":{
        "net_arch":[
          256,
          256
        ],
        "activation_fn":"ELU",
        "ortho_init":"sb3-default"
      },
      "total_timesteps":150000
    },
    "best_model_path":"models\\dqn\\run_05\\best_model\\best_model.zip",
    "final_model_path":"models\\dqn\\run_05\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":150000.0,
    "eval_callback_mean":141.96666675,
    "eval_callback_std":44.3162530827,
    "mean_ep_length":50.0,
    "source_file":"dqn\\run_05\\eval_logs\\evaluations.npz",
    "score_for_rank":157.862500125,
    "reward_rank":3.0
  },
  {
    "algo":"DQN",
    "run_name":"run_07",
    "metadata_source":"run",
    "training_walltime_sec":1044.1834072,
    "eval_mean_reward":156.28333325,
    "eval_std_reward":41.5187340828,
    "callback_best_mean_reward":149.254166625,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0006,
      "gamma":0.97,
      "buffer_size":60000,
      "batch_size":128,
      "train_freq":4,
      "gradient_steps":2,
      "target_update_interval":800,
      "exploration_fraction":0.18,
      "exploration_final_eps":0.02,
      "learning_starts":1800,
      "policy_kwargs":{
        "net_arch":[
          256,
          128
        ],
        "activation_fn":"Tanh",
        "ortho_init":"sb3-default"
      },
      "total_timesteps":150000
    },
    "best_model_path":"models\\dqn\\run_07\\best_model\\best_model.zip",
    "final_model_path":"models\\dqn\\run_07\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":150000.0,
    "eval_callback_mean":127.87083325,
    "eval_callback_std":30.2258647696,
    "mean_ep_length":50.0,
    "source_file":"dqn\\run_07\\eval_logs\\evaluations.npz",
    "score_for_rank":156.28333325,
    "reward_rank":4.0
  },
  {
    "algo":"DQN",
    "run_name":"run_06",
    "metadata_source":"run",
    "training_walltime_sec":1525.258521,
    "eval_mean_reward":148.39166675,
    "eval_std_reward":56.4977501532,
    "callback_best_mean_reward":160.3708335,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0004,
      "gamma":0.98,
      "buffer_size":90000,
      "batch_size":256,
      "train_freq":8,
      "gradient_steps":4,
      "target_update_interval":1000,
      "exploration_fraction":0.2,
      "exploration_final_eps":0.01,
      "learning_starts":2500,
      "policy_kwargs":{
        "net_arch":[
          256,
          256,
          128
        ],
        "activation_fn":"ReLU",
        "ortho_init":"sb3-default"
      },
      "total_timesteps":150000
    },
    "best_model_path":"models\\dqn\\run_06\\best_model\\best_model.zip",
    "final_model_path":"models\\dqn\\run_06\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":150000.0,
    "eval_callback_mean":135.145833375,
    "eval_callback_std":47.2989280543,
    "mean_ep_length":50.0,
    "source_file":"dqn\\run_06\\eval_logs\\evaluations.npz",
    "score_for_rank":148.39166675,
    "reward_rank":5.0
  },
  {
    "algo":"DQN",
    "run_name":"run_03",
    "metadata_source":"run",
    "training_walltime_sec":1486.2742968999,
    "eval_mean_reward":125.924999875,
    "eval_std_reward":46.1532254183,
    "callback_best_mean_reward":162.583333375,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0003,
      "gamma":0.97,
      "buffer_size":50000,
      "batch_size":64,
      "train_freq":1,
      "gradient_steps":1,
      "target_update_interval":500,
      "exploration_fraction":0.3,
      "exploration_final_eps":0.02,
      "learning_starts":1000,
      "policy_kwargs":{
        "net_arch":[
          128,
          128
        ],
        "activation_fn":"ReLU",
        "ortho_init":"sb3-default"
      },
      "total_timesteps":150000
    },
    "best_model_path":"models\\dqn\\run_03\\best_model\\best_model.zip",
    "final_model_path":"models\\dqn\\run_03\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":150000.0,
    "eval_callback_mean":162.583333375,
    "eval_callback_std":45.6950761806,
    "mean_ep_length":50.0,
    "source_file":"dqn\\run_03\\eval_logs\\evaluations.npz",
    "score_for_rank":125.924999875,
    "reward_rank":6.0
  },
  {
    "algo":"DQN",
    "run_name":"run_02",
    "metadata_source":"run",
    "training_walltime_sec":483.31024,
    "eval_mean_reward":122.21666675,
    "eval_std_reward":58.9654679457,
    "callback_best_mean_reward":150.995833375,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.00075,
      "gamma":0.98,
      "buffer_size":80000,
      "batch_size":256,
      "train_freq":4,
      "gradient_steps":1,
      "target_update_interval":750,
      "exploration_fraction":0.15,
      "exploration_final_eps":0.02,
      "learning_starts":1500,
      "policy_kwargs":{
        "net_arch":[
          256,
          128
        ],
        "activation_fn":"ReLU",
        "ortho_init":"sb3-default"
      },
      "total_timesteps":150000
    },
    "best_model_path":"models\\dqn\\run_02\\best_model\\best_model.zip",
    "final_model_path":"models\\dqn\\run_02\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":150000.0,
    "eval_callback_mean":150.995833375,
    "eval_callback_std":50.9265330574,
    "mean_ep_length":50.0,
    "source_file":"dqn\\run_02\\eval_logs\\evaluations.npz",
    "score_for_rank":122.21666675,
    "reward_rank":7.0
  },
  {
    "algo":"DQN",
    "run_name":"run_09",
    "metadata_source":"run",
    "training_walltime_sec":1014.3120784999,
    "eval_mean_reward":103.466666625,
    "eval_std_reward":54.1937881331,
    "callback_best_mean_reward":86.941666625,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0002,
      "gamma":0.99,
      "buffer_size":150000,
      "batch_size":256,
      "train_freq":16,
      "gradient_steps":4,
      "target_update_interval":2000,
      "exploration_fraction":0.1,
      "exploration_final_eps":0.01,
      "learning_starts":5000,
      "policy_kwargs":{
        "net_arch":[
          512,
          256
        ],
        "activation_fn":"ReLU",
        "ortho_init":"sb3-default"
      },
      "total_timesteps":150000
    },
    "best_model_path":"models\\dqn\\run_09\\best_model\\best_model.zip",
    "final_model_path":"models\\dqn\\run_09\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":150000.0,
    "eval_callback_mean":86.941666625,
    "eval_callback_std":40.641019063,
    "mean_ep_length":50.0,
    "source_file":"dqn\\run_09\\eval_logs\\evaluations.npz",
    "score_for_rank":103.466666625,
    "reward_rank":8.0
  },
  {
    "algo":"DQN",
    "run_name":"run_01",
    "metadata_source":"run",
    "training_walltime_sec":490.4536504,
    "eval_mean_reward":95.912499875,
    "eval_std_reward":44.9030249925,
    "callback_best_mean_reward":108.495833375,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0005,
      "gamma":0.99,
      "buffer_size":100000,
      "batch_size":128,
      "train_freq":8,
      "gradient_steps":2,
      "target_update_interval":1000,
      "exploration_fraction":0.2,
      "exploration_final_eps":0.01,
      "learning_starts":2000,
      "policy_kwargs":{
        "net_arch":[
          256,
          256
        ],
        "activation_fn":"ReLU",
        "ortho_init":"sb3-default"
      },
      "total_timesteps":150000
    },
    "best_model_path":"models\\dqn\\run_01\\best_model\\best_model.zip",
    "final_model_path":"models\\dqn\\run_01\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":150000.0,
    "eval_callback_mean":108.495833375,
    "eval_callback_std":49.0064806124,
    "mean_ep_length":50.0,
    "source_file":"dqn\\run_01\\eval_logs\\evaluations.npz",
    "score_for_rank":95.912499875,
    "reward_rank":9.0
  },
  {
    "algo":"DQN",
    "run_name":"run_04",
    "metadata_source":"run",
    "training_walltime_sec":760.2397219,
    "eval_mean_reward":-50.49583325,
    "eval_std_reward":2.2787935251,
    "callback_best_mean_reward":-53.825,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0001,
      "gamma":0.99,
      "buffer_size":120000,
      "batch_size":128,
      "train_freq":16,
      "gradient_steps":4,
      "target_update_interval":1500,
      "exploration_fraction":0.1,
      "exploration_final_eps":0.005,
      "learning_starts":4000,
      "policy_kwargs":{
        "net_arch":[
          512,
          256
        ],
        "activation_fn":"ReLU",
        "ortho_init":"sb3-default"
      },
      "total_timesteps":150000
    },
    "best_model_path":"models\\dqn\\run_04\\best_model\\best_model.zip",
    "final_model_path":"models\\dqn\\run_04\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":150000.0,
    "eval_callback_mean":-57.379166625,
    "eval_callback_std":5.5568759815,
    "mean_ep_length":50.0,
    "source_file":"dqn\\run_04\\eval_logs\\evaluations.npz",
    "score_for_rank":-50.49583325,
    "reward_rank":10.0
  },
  {
    "algo":"PPO",
    "run_name":"run_08",
    "metadata_source":"run",
    "training_walltime_sec":583.2656159999,
    "eval_mean_reward":171.39583325,
    "eval_std_reward":33.5292304155,
    "callback_best_mean_reward":165.291666625,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0006,
      "gamma":0.97,
      "n_steps":1024,
      "batch_size":256,
      "gae_lambda":0.95,
      "clip_range":0.25,
      "ent_coef":0.015,
      "vf_coef":0.5,
      "max_grad_norm":0.6,
      "policy_kwargs":{
        "net_arch":[
          256,
          256
        ],
        "activation_fn":"ReLU",
        "ortho_init":true
      },
      "total_timesteps":250000
    },
    "best_model_path":"models\\ppo\\run_08\\best_model\\best_model.zip",
    "final_model_path":"models\\ppo\\run_08\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":250000.0,
    "eval_callback_mean":145.979166625,
    "eval_callback_std":58.3011029666,
    "mean_ep_length":50.0,
    "source_file":"ppo\\run_08\\eval_logs\\evaluations.npz",
    "score_for_rank":171.39583325,
    "reward_rank":1.0
  },
  {
    "algo":"PPO",
    "run_name":"run_03",
    "metadata_source":"run",
    "training_walltime_sec":705.5527372001,
    "eval_mean_reward":145.541666625,
    "eval_std_reward":58.5695022785,
    "callback_best_mean_reward":154.5458335,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0005,
      "gamma":0.97,
      "n_steps":1024,
      "batch_size":128,
      "gae_lambda":0.9,
      "clip_range":0.2,
      "ent_coef":0.02,
      "vf_coef":0.4,
      "max_grad_norm":0.5,
      "policy_kwargs":{
        "net_arch":[
          256,
          256
        ],
        "activation_fn":"Tanh",
        "ortho_init":false
      },
      "total_timesteps":250000
    },
    "best_model_path":"models\\ppo\\run_03\\best_model\\best_model.zip",
    "final_model_path":"models\\ppo\\run_03\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":250000.0,
    "eval_callback_mean":154.5458335,
    "eval_callback_std":56.3740900369,
    "mean_ep_length":50.0,
    "source_file":"ppo\\run_03\\eval_logs\\evaluations.npz",
    "score_for_rank":145.541666625,
    "reward_rank":2.0
  },
  {
    "algo":"PPO",
    "run_name":"run_07",
    "metadata_source":"run",
    "training_walltime_sec":627.7584043,
    "eval_mean_reward":134.454166625,
    "eval_std_reward":60.0336963565,
    "callback_best_mean_reward":166.112500125,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0004,
      "gamma":0.98,
      "n_steps":1280,
      "batch_size":256,
      "gae_lambda":0.93,
      "clip_range":0.3,
      "ent_coef":0.01,
      "vf_coef":0.4,
      "max_grad_norm":0.5,
      "policy_kwargs":{
        "net_arch":[
          256,
          128
        ],
        "activation_fn":"ReLU",
        "ortho_init":false
      },
      "total_timesteps":250000
    },
    "best_model_path":"models\\ppo\\run_07\\best_model\\best_model.zip",
    "final_model_path":"models\\ppo\\run_07\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":250000.0,
    "eval_callback_mean":135.483333375,
    "eval_callback_std":53.061625679,
    "mean_ep_length":50.0,
    "source_file":"ppo\\run_07\\eval_logs\\evaluations.npz",
    "score_for_rank":134.454166625,
    "reward_rank":3.0
  },
  {
    "algo":"PPO",
    "run_name":"run_04",
    "metadata_source":"run",
    "training_walltime_sec":628.5748384,
    "eval_mean_reward":108.45000025,
    "eval_std_reward":42.3858172245,
    "callback_best_mean_reward":100.3875,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0007,
      "gamma":0.98,
      "n_steps":2048,
      "batch_size":512,
      "gae_lambda":0.92,
      "clip_range":0.15,
      "ent_coef":0.005,
      "vf_coef":0.6,
      "max_grad_norm":0.5,
      "policy_kwargs":{
        "net_arch":[
          512,
          256
        ],
        "activation_fn":"ReLU",
        "ortho_init":true
      },
      "total_timesteps":250000
    },
    "best_model_path":"models\\ppo\\run_04\\best_model\\best_model.zip",
    "final_model_path":"models\\ppo\\run_04\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":250000.0,
    "eval_callback_mean":100.3875,
    "eval_callback_std":43.90633001,
    "mean_ep_length":50.0,
    "source_file":"ppo\\run_04\\eval_logs\\evaluations.npz",
    "score_for_rank":108.45000025,
    "reward_rank":4.0
  },
  {
    "algo":"PPO",
    "run_name":"run_00",
    "metadata_source":"run",
    "training_walltime_sec":1273.6833551,
    "eval_mean_reward":105.858333375,
    "eval_std_reward":39.1128414676,
    "callback_best_mean_reward":146.2791665,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0003,
      "gamma":0.99,
      "n_steps":1024,
      "batch_size":256,
      "gae_lambda":0.95,
      "clip_range":0.2,
      "ent_coef":0.01,
      "vf_coef":0.5,
      "max_grad_norm":0.5,
      "policy_kwargs":{
        "net_arch":[
          256,
          256
        ],
        "activation_fn":"ReLU",
        "ortho_init":true
      },
      "total_timesteps":250000
    },
    "best_model_path":"models\\ppo\\run_00\\best_model\\best_model.zip",
    "final_model_path":"models\\ppo\\run_00\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":250000.0,
    "eval_callback_mean":134.337500125,
    "eval_callback_std":33.6231007158,
    "mean_ep_length":50.0,
    "source_file":"ppo\\run_00\\eval_logs\\evaluations.npz",
    "score_for_rank":105.858333375,
    "reward_rank":5.0
  },
  {
    "algo":"PPO",
    "run_name":"run_05",
    "metadata_source":"run",
    "training_walltime_sec":834.3297074001,
    "eval_mean_reward":82.525,
    "eval_std_reward":43.8940193485,
    "callback_best_mean_reward":132.037500125,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0003,
      "gamma":0.99,
      "n_steps":768,
      "batch_size":128,
      "gae_lambda":0.95,
      "clip_range":0.2,
      "ent_coef":0.01,
      "vf_coef":0.5,
      "max_grad_norm":0.5,
      "policy_kwargs":{
        "net_arch":[
          256,
          128
        ],
        "activation_fn":"ELU",
        "ortho_init":false
      },
      "total_timesteps":250000
    },
    "best_model_path":"models\\ppo\\run_05\\best_model\\best_model.zip",
    "final_model_path":"models\\ppo\\run_05\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":250000.0,
    "eval_callback_mean":88.866666625,
    "eval_callback_std":38.0977360799,
    "mean_ep_length":50.0,
    "source_file":"ppo\\run_05\\eval_logs\\evaluations.npz",
    "score_for_rank":82.525,
    "reward_rank":6.0
  },
  {
    "algo":"PPO",
    "run_name":"run_01",
    "metadata_source":"run",
    "training_walltime_sec":1018.0991939,
    "eval_mean_reward":78.145833375,
    "eval_std_reward":35.7531385351,
    "callback_best_mean_reward":91.220833375,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.00025,
      "gamma":0.98,
      "n_steps":2048,
      "batch_size":256,
      "gae_lambda":0.95,
      "clip_range":0.2,
      "ent_coef":0.005,
      "vf_coef":0.4,
      "max_grad_norm":0.6,
      "policy_kwargs":{
        "net_arch":[
          256,
          128
        ],
        "activation_fn":"ReLU",
        "ortho_init":false
      },
      "total_timesteps":250000
    },
    "best_model_path":"models\\ppo\\run_01\\best_model\\best_model.zip",
    "final_model_path":"models\\ppo\\run_01\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":250000.0,
    "eval_callback_mean":91.220833375,
    "eval_callback_std":35.111393936,
    "mean_ep_length":50.0,
    "source_file":"ppo\\run_01\\eval_logs\\evaluations.npz",
    "score_for_rank":78.145833375,
    "reward_rank":7.0
  },
  {
    "algo":"PPO",
    "run_name":"run_09",
    "metadata_source":"run",
    "training_walltime_sec":678.6156157,
    "eval_mean_reward":-15.824999875,
    "eval_std_reward":132.3561103474,
    "callback_best_mean_reward":75.895833375,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.00015,
      "gamma":0.99,
      "n_steps":1536,
      "batch_size":256,
      "gae_lambda":0.96,
      "clip_range":0.2,
      "ent_coef":0.0,
      "vf_coef":0.5,
      "max_grad_norm":0.8,
      "policy_kwargs":{
        "net_arch":[
          256,
          256,
          128
        ],
        "activation_fn":"Tanh",
        "ortho_init":true
      },
      "total_timesteps":250000
    },
    "best_model_path":"models\\ppo\\run_09\\best_model\\best_model.zip",
    "final_model_path":"models\\ppo\\run_09\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":250000.0,
    "eval_callback_mean":38.8166665,
    "eval_callback_std":44.1451614857,
    "mean_ep_length":50.0,
    "source_file":"ppo\\run_09\\eval_logs\\evaluations.npz",
    "score_for_rank":-15.824999875,
    "reward_rank":8.0
  },
  {
    "algo":"PPO",
    "run_name":"run_06",
    "metadata_source":"run",
    "training_walltime_sec":658.3248422999,
    "eval_mean_reward":-56.145833375,
    "eval_std_reward":2.8685527374,
    "callback_best_mean_reward":-54.562500125,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0002,
      "gamma":0.995,
      "n_steps":2048,
      "batch_size":256,
      "gae_lambda":0.97,
      "clip_range":0.2,
      "ent_coef":0.0,
      "vf_coef":0.5,
      "max_grad_norm":0.7,
      "policy_kwargs":{
        "net_arch":[
          256,
          256
        ],
        "activation_fn":"Tanh",
        "ortho_init":true
      },
      "total_timesteps":250000
    },
    "best_model_path":"models\\ppo\\run_06\\best_model\\best_model.zip",
    "final_model_path":"models\\ppo\\run_06\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":250000.0,
    "eval_callback_mean":-177.9125,
    "eval_callback_std":63.2273059964,
    "mean_ep_length":50.0,
    "source_file":"ppo\\run_06\\eval_logs\\evaluations.npz",
    "score_for_rank":-56.145833375,
    "reward_rank":9.0
  },
  {
    "algo":"PPO",
    "run_name":"run_02",
    "metadata_source":"run",
    "training_walltime_sec":1654.365423,
    "eval_mean_reward":-61.2875,
    "eval_std_reward":43.764337107,
    "callback_best_mean_reward":-32.37916675,
    "best_smoothed_reward":null,
    "hyperparameters":{
      "learning_rate":0.0001,
      "gamma":0.99,
      "n_steps":1536,
      "batch_size":192,
      "gae_lambda":0.97,
      "clip_range":0.25,
      "ent_coef":0.0,
      "vf_coef":0.5,
      "max_grad_norm":0.7,
      "policy_kwargs":{
        "net_arch":[
          256,
          256,
          128
        ],
        "activation_fn":"ReLU",
        "ortho_init":true
      },
      "total_timesteps":250000
    },
    "best_model_path":"models\\ppo\\run_02\\best_model\\best_model.zip",
    "final_model_path":"models\\ppo\\run_02\\final_model.zip",
    "policy_path":null,
    "episode_rewards_path":null,
    "timestep":250000.0,
    "eval_callback_mean":-32.37916675,
    "eval_callback_std":45.889910321,
    "mean_ep_length":50.0,
    "source_file":"ppo\\run_02\\eval_logs\\evaluations.npz",
    "score_for_rank":-61.2875,
    "reward_rank":10.0
  },
  {
    "algo":"REINFORCE",
    "run_name":"run_04",
    "metadata_source":"run",
    "training_walltime_sec":210.5879146,
    "eval_mean_reward":-54.0916666667,
    "eval_std_reward":2.4004484535,
    "callback_best_mean_reward":null,
    "best_smoothed_reward":-53.5380079839,
    "hyperparameters":{
      "learning_rate":0.0006,
      "gamma":0.98,
      "hidden_layers":[
        256,
        256
      ],
      "entropy_coef":0.001,
      "normalize_returns":true,
      "episodes":500,
      "batch_episodes":3,
      "max_grad_norm":0.5
    },
    "best_model_path":null,
    "final_model_path":null,
    "policy_path":"models\\pg\\run_04\\policy.pt",
    "episode_rewards_path":"models\\pg\\run_04\\episode_rewards.csv",
    "timestep":null,
    "eval_callback_mean":null,
    "eval_callback_std":null,
    "mean_ep_length":null,
    "source_file":null,
    "score_for_rank":-54.0916666667,
    "reward_rank":1.0
  },
  {
    "algo":"REINFORCE",
    "run_name":"run_06",
    "metadata_source":"run",
    "training_walltime_sec":140.1335559,
    "eval_mean_reward":-55.0,
    "eval_std_reward":3.4136978972,
    "callback_best_mean_reward":null,
    "best_smoothed_reward":-61.9351885697,
    "hyperparameters":{
      "learning_rate":0.0004,
      "gamma":0.995,
      "hidden_layers":[
        256,
        128
      ],
      "entropy_coef":0.0,
      "normalize_returns":true,
      "episodes":480,
      "batch_episodes":2,
      "max_grad_norm":0.6
    },
    "best_model_path":null,
    "final_model_path":null,
    "policy_path":"models\\pg\\run_06\\policy.pt",
    "episode_rewards_path":"models\\pg\\run_06\\episode_rewards.csv",
    "timestep":null,
    "eval_callback_mean":null,
    "eval_callback_std":null,
    "mean_ep_length":null,
    "source_file":null,
    "score_for_rank":-55.0,
    "reward_rank":2.0
  },
  {
    "algo":"REINFORCE",
    "run_name":"run_00",
    "metadata_source":"run",
    "training_walltime_sec":40.5972042001,
    "eval_mean_reward":-56.5625,
    "eval_std_reward":3.9220331143,
    "callback_best_mean_reward":null,
    "best_smoothed_reward":-78.6213654131,
    "hyperparameters":{
      "learning_rate":0.001,
      "gamma":0.99,
      "hidden_layers":[
        256,
        256
      ],
      "entropy_coef":0.001,
      "normalize_returns":true,
      "episodes":400,
      "batch_episodes":1,
      "max_grad_norm":0.5
    },
    "best_model_path":null,
    "final_model_path":null,
    "policy_path":"models\\pg\\run_00\\policy.pt",
    "episode_rewards_path":"models\\pg\\run_00\\episode_rewards.csv",
    "timestep":null,
    "eval_callback_mean":null,
    "eval_callback_std":null,
    "mean_ep_length":null,
    "source_file":null,
    "score_for_rank":-56.5625,
    "reward_rank":3.0
  },
  {
    "algo":"REINFORCE",
    "run_name":"run_07",
    "metadata_source":"run",
    "training_walltime_sec":60.1010363001,
    "eval_mean_reward":-146.0875,
    "eval_std_reward":53.9734037835,
    "callback_best_mean_reward":null,
    "best_smoothed_reward":-76.4262613089,
    "hyperparameters":{
      "learning_rate":0.0009,
      "gamma":0.97,
      "hidden_layers":[
        256,
        256
      ],
      "entropy_coef":0.002,
      "normalize_returns":true,
      "episodes":360,
      "batch_episodes":1,
      "max_grad_norm":0.6
    },
    "best_model_path":null,
    "final_model_path":null,
    "policy_path":"models\\pg\\run_07\\policy.pt",
    "episode_rewards_path":"models\\pg\\run_07\\episode_rewards.csv",
    "timestep":null,
    "eval_callback_mean":null,
    "eval_callback_std":null,
    "mean_ep_length":null,
    "source_file":null,
    "score_for_rank":-146.0875,
    "reward_rank":4.0
  },
  {
    "algo":"REINFORCE",
    "run_name":"run_02",
    "metadata_source":"run",
    "training_walltime_sec":64.5458515,
    "eval_mean_reward":-152.7625,
    "eval_std_reward":2.888600079,
    "callback_best_mean_reward":null,
    "best_smoothed_reward":-82.8915257567,
    "hyperparameters":{
      "learning_rate":0.0008,
      "gamma":0.97,
      "hidden_layers":[
        128,
        128
      ],
      "entropy_coef":0.002,
      "normalize_returns":false,
      "episodes":350,
      "batch_episodes":2,
      "max_grad_norm":0.6
    },
    "best_model_path":null,
    "final_model_path":null,
    "policy_path":"models\\pg\\run_02\\policy.pt",
    "episode_rewards_path":"models\\pg\\run_02\\episode_rewards.csv",
    "timestep":null,
    "eval_callback_mean":null,
    "eval_callback_std":null,
    "mean_ep_length":null,
    "source_file":null,
    "score_for_rank":-152.7625,
    "reward_rank":5.0
  },
  {
    "algo":"REINFORCE",
    "run_name":"run_05",
    "metadata_source":"run",
    "training_walltime_sec":101.7929691999,
    "eval_mean_reward":-252.975,
    "eval_std_reward":7.4250280583,
    "callback_best_mean_reward":null,
    "best_smoothed_reward":-77.9211664276,
    "hyperparameters":{
      "learning_rate":0.0012,
      "gamma":0.96,
      "hidden_layers":[
        128,
        128
      ],
      "entropy_coef":0.003,
      "normalize_returns":false,
      "episodes":320,
      "batch_episodes":2,
      "max_grad_norm":0.7
    },
    "best_model_path":null,
    "final_model_path":null,
    "policy_path":"models\\pg\\run_05\\policy.pt",
    "episode_rewards_path":"models\\pg\\run_05\\episode_rewards.csv",
    "timestep":null,
    "eval_callback_mean":null,
    "eval_callback_std":null,
    "mean_ep_length":null,
    "source_file":null,
    "score_for_rank":-252.975,
    "reward_rank":6.0
  },
  {
    "algo":"REINFORCE",
    "run_name":"run_03",
    "metadata_source":"run",
    "training_walltime_sec":43.3944475,
    "eval_mean_reward":-254.2791666667,
    "eval_std_reward":2.2773606495,
    "callback_best_mean_reward":null,
    "best_smoothed_reward":-85.1331597518,
    "hyperparameters":{
      "learning_rate":0.0003,
      "gamma":0.99,
      "hidden_layers":[
        256,
        256,
        128
      ],
      "entropy_coef":0.0,
      "normalize_returns":true,
      "episodes":450,
      "batch_episodes":1,
      "max_grad_norm":0.6
    },
    "best_model_path":null,
    "final_model_path":null,
    "policy_path":"models\\pg\\run_03\\policy.pt",
    "episode_rewards_path":"models\\pg\\run_03\\episode_rewards.csv",
    "timestep":null,
    "eval_callback_mean":null,
    "eval_callback_std":null,
    "mean_ep_length":null,
    "source_file":null,
    "score_for_rank":-254.2791666667,
    "reward_rank":7.0
  },
  {
    "algo":"REINFORCE",
    "run_name":"run_08",
    "metadata_source":"run",
    "training_walltime_sec":137.8059925,
    "eval_mean_reward":-256.2791666667,
    "eval_std_reward":4.1878109337,
    "callback_best_mean_reward":null,
    "best_smoothed_reward":-71.9865575113,
    "hyperparameters":{
      "learning_rate":0.0007,
      "gamma":0.99,
      "hidden_layers":[
        256,
        256
      ],
      "entropy_coef":0.0015,
      "normalize_returns":true,
      "episodes":420,
      "batch_episodes":2,
      "max_grad_norm":0.5
    },
    "best_model_path":null,
    "final_model_path":null,
    "policy_path":"models\\pg\\run_08\\policy.pt",
    "episode_rewards_path":"models\\pg\\run_08\\episode_rewards.csv",
    "timestep":null,
    "eval_callback_mean":null,
    "eval_callback_std":null,
    "mean_ep_length":null,
    "source_file":null,
    "score_for_rank":-256.2791666667,
    "reward_rank":8.0
  },
  {
    "algo":"REINFORCE",
    "run_name":"run_09",
    "metadata_source":"run",
    "training_walltime_sec":307.0266058,
    "eval_mean_reward":-256.3416666667,
    "eval_std_reward":4.1443988306,
    "callback_best_mean_reward":null,
    "best_smoothed_reward":-55.7231275321,
    "hyperparameters":{
      "learning_rate":0.00025,
      "gamma":0.995,
      "hidden_layers":[
        256,
        256,
        128
      ],
      "entropy_coef":0.0,
      "normalize_returns":true,
      "episodes":600,
      "batch_episodes":3,
      "max_grad_norm":0.6
    },
    "best_model_path":null,
    "final_model_path":null,
    "policy_path":"models\\pg\\run_09\\policy.pt",
    "episode_rewards_path":"models\\pg\\run_09\\episode_rewards.csv",
    "timestep":null,
    "eval_callback_mean":null,
    "eval_callback_std":null,
    "mean_ep_length":null,
    "source_file":null,
    "score_for_rank":-256.3416666667,
    "reward_rank":9.0
  },
  {
    "algo":"REINFORCE",
    "run_name":"run_01",
    "metadata_source":"run",
    "training_walltime_sec":52.0083278,
    "eval_mean_reward":-257.3166666667,
    "eval_std_reward":4.0650611585,
    "callback_best_mean_reward":null,
    "best_smoothed_reward":-71.1860460192,
    "hyperparameters":{
      "learning_rate":0.0005,
      "gamma":0.98,
      "hidden_layers":[
        256,
        128
      ],
      "entropy_coef":0.0,
      "normalize_returns":true,
      "episodes":300,
      "batch_episodes":2,
      "max_grad_norm":0.5
    },
    "best_model_path":null,
    "final_model_path":null,
    "policy_path":"models\\pg\\run_01\\policy.pt",
    "episode_rewards_path":"models\\pg\\run_01\\episode_rewards.csv",
    "timestep":null,
    "eval_callback_mean":null,
    "eval_callback_std":null,
    "mean_ep_length":null,
    "source_file":null,
    "score_for_rank":-257.3166666667,
    "reward_rank":10.0
  }
]